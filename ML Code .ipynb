{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import itertools\n",
    "import csv,codecs,nltk,re\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn import cross_validation#    from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, NuSVC , LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2 = pd.read_csv('E:\\cluster data\\One_File_nonnormalizenew2.txt', sep=\"*\")\n",
    "data = pd.read_csv('E:\\\\new data2019\\\\One_File_44000 clean.txt', sep=\"*\")\n",
    "\n",
    "data.columns = [\"text\", \"class1\"]\n",
    "data.dropna(inplace=True)\n",
    "#data2.columns = [\"text\", \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44331"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tv          4056\n",
       "ads         4040\n",
       "politic     4037\n",
       "tech        4036\n",
       "food        4032\n",
       "health      4028\n",
       "porno       4026\n",
       "eco         4024\n",
       "religion    4020\n",
       "weather     4020\n",
       "sport       4012\n",
       "Name: class1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.class1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.groupby('class1').apply(lambda x: x.iloc[:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion    4000\n",
       "sport       4000\n",
       "tech        4000\n",
       "food        4000\n",
       "tv          4000\n",
       "politic     4000\n",
       "eco         4000\n",
       "ads         4000\n",
       "health      4000\n",
       "porno       4000\n",
       "weather     4000\n",
       "Name: class1, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.class1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = re.sub(\"[إﺁأٱآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"_\", \" \", text)\n",
    "    text = re.sub(\"#\", \" \", text)\n",
    "    \n",
    "    text = re.sub(\"ؤ\", \"و\", text)\n",
    "    #text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    noise = re.compile(\"\"\" ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(noise, '', text)\n",
    "    return(text)\n",
    "def stopwordremoval(text):\n",
    "    stop=stopwords.words(\"arabic - Copy\")\n",
    "    needed_words=[]\n",
    "    words=word_tokenize(text)\n",
    "    for w in words:\n",
    "         if len(w)>=2 and w not in stop:\n",
    "                needed_words.append(w)\n",
    "    filterd_sent= \" \".join(needed_words)\n",
    "    return filterd_sent\n",
    "def removenonarabic(text):\n",
    "    n=re.sub(r'[a-zA-Z?]', '', text).strip()\n",
    "    n=re.sub('\\W+',' ', n )\n",
    "    n=re.sub('_','', n )\n",
    "    n = ''.join([i for i in n if not i.isdigit()])\n",
    "    a=re.compile(u\"([^\\u0600-\\u06ff\\ufb50-\\ufdff\\ufe70-\\ufeff\\u0750-\\u077f ])\", re.UNICODE)\n",
    "    n=re.sub(a,'', n)\n",
    "    return n\n",
    "def stemming(text):\n",
    "    st = ISRIStemmer()\n",
    "    stemmed_words=[]\n",
    "    words=word_tokenize(text)\n",
    "    for w in words:\n",
    "        stemmed_words.append(st.stem(w))\n",
    "    stemmed_sent=\" \".join(stemmed_words)\n",
    "    return stemmed_sent\n",
    "def remove_repeating_char(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "def preparedatasets(data):\n",
    "    sentences=[]\n",
    "    for index,r in data.iterrows():\n",
    "        text=normalize(r['text'])\n",
    "        text=stopwordremoval(text)\n",
    "        text=removenonarabic(text)\n",
    "        #text=stemming(text)\n",
    "        sentences.append([text,r['class1']])\n",
    "    df_sentence=DataFrame(sentences, columns=[\"text\", \"class1\"])\n",
    "    return df_sentence        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=preparedatasets(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['text']\n",
    "y=data['class1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data['text'], data['class1'],test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dropna(inplace=True)\n",
    "y_train.dropna(inplace=True)\n",
    "\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=[MultinomialNB, BernoulliNB,LogisticRegression,SGDClassifier,SVC, NuSVC , LinearSVC,DecisionTreeClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(data):\n",
    "    cc = pd.DataFrame()\n",
    "    cc['countt']=[len(t.split())for t in data.text] \n",
    "    \n",
    "\n",
    "    return cc.sum().countt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748827\n"
     ]
    }
   ],
   "source": [
    "print(get_count(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dd=data[data['class1']=='politic']\n",
    "#dd.to_csv(\"e:\\\\politic.txt\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(clf,X,Y):\n",
    "        X_train, X_text, Y_train, Y_test=\\\n",
    "        cross_validation.train_test_split(X,Y,test_size=0.1, random_state=43)\n",
    "        #print(\"Y train \",X_train)\n",
    "        classifier=clf()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        predict=cross_validation.cross_val_predict(classifier,X_text,Y_test, cv=10)#cv=10\n",
    "        scores=cross_validation.cross_val_score(classifier,X_text,Y_test, cv=10)\n",
    "       # print(Y_test,predict)\n",
    "        print(\"Accuracy of %s: %0.2f (+/- %0.2f)\"%(classifier, scores.mean(),scores.std()*2))#standard deviation\n",
    "        print(classification_report(Y_test,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(clf):\n",
    "   # data = pd.read_csv('e:\\One_File_nonnormalizenew2norm.txt', sep=\"*\")\n",
    "  #  data.columns = [\"text\", \"class\"]\n",
    "  #  data.dropna(inplace=True)\n",
    "  #  new_data=preparedatasets(data)\n",
    "    data, target=data['text'], new_data['class1']\n",
    "    #print(\"class\",target)\n",
    "    tfidf_data=featureextraction(data)\n",
    "   # print(tfidf_data)\n",
    "    learning(clf,tfidf_data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import *\n",
    "result=\"Classifier\"+'*'+\"dataset_size * Accuracy * f1_score * Recall * precision\"+\"\\n\"\n",
    "def featureextraction2(data , clf):\n",
    "    data.dropna(inplace=True)\n",
    "    global result\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data['text'], data['class1'],test_size=0.20, random_state = 0)\n",
    "    vectorizer = TfidfVectorizer( analyzer='word',smooth_idf=True, ngram_range=(1,1))\n",
    "    vectorizer.fit(X_train)\n",
    "    X_train_vectorized = vectorizer.transform(X_train)\n",
    "    #clf = LogisticRegression()\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    predictions = clf.predict(vectorizer.transform(X_test))\n",
    "    result +=clf.__class__.__name__+'*'+str(get_count(data))+'*'+str(accuracy_score(y_test, predictions))+'*'+str(f1_score(y_test,predictions,average='weighted'))+'*'+str(recall_score(y_test, predictions,average='weighted'))+'*'+str(precision_score(y_test, predictions,average='weighted'))+'\\n'\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"accuracy\",accuracy_score(y_test, predictions))\n",
    "    print(\"f1_score\",f1_score(y_test, predictions,average='weighted'))\n",
    "    print(\"recall\",recall_score(y_test, predictions,average='weighted'))\n",
    "    print(\"precision\",precision_score(y_test, predictions,average='weighted'))    \n",
    "    print ('\\n clasification report:\\n', classification_report(y_test, predictions))\n",
    "    print (' confussion matrix:\\n',confusion_matrix(y_test, predictions))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplly 9 classifier in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl=[MultinomialNB, BernoulliNB,LogisticRegression,SGDClassifier,SVC, NuSVC , LinearSVC,DecisionTreeClassifier,RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "accuracy 0.9682954545454545\n",
      "f1_score 0.9681784826972638\n",
      "recall 0.9682954545454545\n",
      "precision 0.9682389370159301\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.96      0.99      0.98       795\n",
      "         eco       0.94      0.91      0.93       821\n",
      "        food       1.00      0.99      0.99       820\n",
      "      health       0.96      0.99      0.98       794\n",
      "     politic       0.94      0.92      0.93       790\n",
      "       porno       0.99      0.99      0.99       809\n",
      "    religion       0.99      0.99      0.99       780\n",
      "       sport       0.98      0.98      0.98       831\n",
      "        tech       0.97      0.95      0.96       816\n",
      "          tv       0.95      0.97      0.96       754\n",
      "     weather       0.97      0.97      0.97       790\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8800\n",
      "   macro avg       0.97      0.97      0.97      8800\n",
      "weighted avg       0.97      0.97      0.97      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[789   0   1   2   0   0   0   2   0   0   1]\n",
      " [ 19 749   1   2  23   0   0   5  12   7   3]\n",
      " [  2   0 811   3   0   1   0   0   0   1   2]\n",
      " [  0   1   0 784   2   0   2   0   2   2   1]\n",
      " [  3  29   1   2 723   0   2   5   7   8  10]\n",
      " [  1   0   0   2   0 804   0   0   0   1   1]\n",
      " [  1   0   0   2   1   0 771   0   0   3   2]\n",
      " [  0   0   0   4   2   0   1 816   2   6   0]\n",
      " [  3  16   1  10   8   0   0   3 772   3   0]\n",
      " [  2   1   0   2   7   5   1   3   1 732   0]\n",
      " [  1   2   0   0   6   0   1   0   1   9 770]]\n",
      "BernoulliNB\n",
      "accuracy 0.9393181818181818\n",
      "f1_score 0.9398609358637959\n",
      "recall 0.9393181818181818\n",
      "precision 0.9457076535805435\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.99      0.95      0.97       795\n",
      "         eco       0.80      0.96      0.87       821\n",
      "        food       0.86      1.00      0.93       820\n",
      "      health       1.00      0.81      0.89       794\n",
      "     politic       0.88      0.92      0.90       790\n",
      "       porno       0.99      1.00      0.99       809\n",
      "    religion       1.00      0.95      0.98       780\n",
      "       sport       0.98      0.98      0.98       831\n",
      "        tech       0.95      0.95      0.95       816\n",
      "          tv       0.97      0.93      0.95       754\n",
      "     weather       1.00      0.87      0.93       790\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      8800\n",
      "   macro avg       0.95      0.94      0.94      8800\n",
      "weighted avg       0.95      0.94      0.94      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[756  20   8   2   0   2   0   1   4   2   0]\n",
      " [  1 791   4   0  19   0   0   1   5   0   0]\n",
      " [  0   0 820   0   0   0   0   0   0   0   0]\n",
      " [  0  37  61 642  24   1   0   2  25   2   0]\n",
      " [  0  56   1   0 725   0   0   2   5   1   0]\n",
      " [  0   1   2   1   0 805   0   0   0   0   0]\n",
      " [  0   4  20   0   6   1 744   2   0   3   0]\n",
      " [  0   3   3   0   4   0   0 818   2   1   0]\n",
      " [  0  24   4   0   9   0   0   1 776   2   0]\n",
      " [  1  14  11   0  17   6   0   5   2 698   0]\n",
      " [  2  42  18   0  24   0   1   3   2   7 691]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "accuracy 0.9623863636363637\n",
      "f1_score 0.962788075382401\n",
      "recall 0.9623863636363637\n",
      "precision 0.9639803609228108\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.98      0.98      0.98       795\n",
      "         eco       0.93      0.90      0.91       821\n",
      "        food       0.99      0.98      0.99       820\n",
      "      health       0.96      0.98      0.97       794\n",
      "     politic       0.84      0.95      0.89       790\n",
      "       porno       1.00      0.99      0.99       809\n",
      "    religion       0.98      0.98      0.98       780\n",
      "       sport       0.99      0.97      0.98       831\n",
      "        tech       0.96      0.94      0.95       816\n",
      "          tv       0.99      0.96      0.97       754\n",
      "     weather       0.99      0.96      0.98       790\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      8800\n",
      "   macro avg       0.96      0.96      0.96      8800\n",
      "weighted avg       0.96      0.96      0.96      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[778   2   1   4   3   1   1   2   2   1   0]\n",
      " [  3 739   1   3  57   0   0   1  16   0   1]\n",
      " [  2   1 805   6   1   0   1   0   1   0   3]\n",
      " [  0   1   3 778   8   0   2   0   2   0   0]\n",
      " [  0  22   0   1 752   0   3   1   9   0   2]\n",
      " [  2   0   0   2   4 797   1   0   2   1   0]\n",
      " [  0   1   0   4   6   0 766   0   0   3   0]\n",
      " [  0   3   0   4  14   0   1 806   2   1   0]\n",
      " [  2  21   2   7  14   0   0   5 765   0   0]\n",
      " [  3   2   1   1  18   0   2   1   2 724   0]\n",
      " [  0   6   0   0  17   1   5   0   0   2 759]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier\n",
      "accuracy 0.9681818181818181\n",
      "f1_score 0.9682001613368147\n",
      "recall 0.9681818181818181\n",
      "precision 0.9684945661652521\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.98      0.98      0.98       795\n",
      "         eco       0.94      0.90      0.92       821\n",
      "        food       0.99      0.99      0.99       820\n",
      "      health       0.96      0.98      0.97       794\n",
      "     politic       0.89      0.94      0.91       790\n",
      "       porno       1.00      1.00      1.00       809\n",
      "    religion       0.98      0.99      0.98       780\n",
      "       sport       0.98      0.98      0.98       831\n",
      "        tech       0.96      0.95      0.95       816\n",
      "          tv       0.99      0.96      0.98       754\n",
      "     weather       0.98      0.97      0.98       790\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8800\n",
      "   macro avg       0.97      0.97      0.97      8800\n",
      "weighted avg       0.97      0.97      0.97      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[782   1   2   4   0   0   1   2   1   1   1]\n",
      " [  8 739   3   4  45   0   0   3  17   0   2]\n",
      " [  0   1 812   3   0   1   0   0   0   0   3]\n",
      " [  0   1   3 780   3   0   3   0   2   1   1]\n",
      " [  2  20   0   3 741   0   5   5   8   2   4]\n",
      " [  0   0   0   2   1 805   0   0   0   1   0]\n",
      " [  0   0   0   3   2   0 774   0   0   1   0]\n",
      " [  0   1   0   4   4   0   1 818   2   1   0]\n",
      " [  2  18   1   5  11   0   0   5 773   1   0]\n",
      " [  2   1   1   1  13   0   3   2   2 727   2]\n",
      " [  0   1   0   0  13   1   5   0   0   1 769]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "accuracy 0.08568181818181818\n",
      "f1_score 0.013523988048794414\n",
      "recall 0.08568181818181818\n",
      "precision 0.007341373966942148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.00      0.00      0.00       795\n",
      "         eco       0.00      0.00      0.00       821\n",
      "        food       0.00      0.00      0.00       820\n",
      "      health       0.00      0.00      0.00       794\n",
      "     politic       0.00      0.00      0.00       790\n",
      "       porno       0.00      0.00      0.00       809\n",
      "    religion       0.00      0.00      0.00       780\n",
      "       sport       0.00      0.00      0.00       831\n",
      "        tech       0.00      0.00      0.00       816\n",
      "          tv       0.09      1.00      0.16       754\n",
      "     weather       0.00      0.00      0.00       790\n",
      "\n",
      "   micro avg       0.09      0.09      0.09      8800\n",
      "   macro avg       0.01      0.09      0.01      8800\n",
      "weighted avg       0.01      0.09      0.01      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[  0   0   0   0   0   0   0   0   0 795   0]\n",
      " [  0   0   0   0   0   0   0   0   0 821   0]\n",
      " [  0   0   0   0   0   0   0   0   0 820   0]\n",
      " [  0   0   0   0   0   0   0   0   0 794   0]\n",
      " [  0   0   0   0   0   0   0   0   0 790   0]\n",
      " [  0   0   0   0   0   0   0   0   0 809   0]\n",
      " [  0   0   0   0   0   0   0   0   0 780   0]\n",
      " [  0   0   0   0   0   0   0   0   0 831   0]\n",
      " [  0   0   0   0   0   0   0   0   0 816   0]\n",
      " [  0   0   0   0   0   0   0   0   0 754   0]\n",
      " [  0   0   0   0   0   0   0   0   0 790   0]]\n",
      "NuSVC\n",
      "accuracy 0.8023863636363636\n",
      "f1_score 0.8192527273590287\n",
      "recall 0.8023863636363636\n",
      "precision 0.8807192745978831\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.98      0.92      0.95       795\n",
      "         eco       0.57      0.83      0.68       821\n",
      "        food       0.98      0.77      0.86       820\n",
      "      health       0.87      0.96      0.91       794\n",
      "     politic       0.42      0.92      0.58       790\n",
      "       porno       1.00      0.75      0.85       809\n",
      "    religion       0.95      0.87      0.91       780\n",
      "       sport       1.00      0.66      0.80       831\n",
      "        tech       0.93      0.65      0.77       816\n",
      "          tv       0.98      0.74      0.85       754\n",
      "     weather       1.00      0.76      0.87       790\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      8800\n",
      "   macro avg       0.88      0.80      0.82      8800\n",
      "weighted avg       0.88      0.80      0.82      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[732  23   0  13  16   0   1   0   8   2   0]\n",
      " [  4 685   0   2 129   0   0   0   1   0   0]\n",
      " [  1  45 629  35 106   0   1   0   0   2   1]\n",
      " [  0  12   0 763  16   0   0   0   3   0   0]\n",
      " [  2  56   0   4 724   0   3   0   1   0   0]\n",
      " [  0   5   0   5 185 603   0   0   8   3   0]\n",
      " [  0  36   1   6  57   0 678   0   1   1   0]\n",
      " [  0  23   2  16 230   0   1 551   8   0   0]\n",
      " [  3 225   5  15  33   0   0   1 534   0   0]\n",
      " [  3  66   2   6 112   0   1   0   5 559   0]\n",
      " [  0  30   0   9 115   0  25   0   6   2 603]]\n",
      "LinearSVC\n",
      "accuracy 0.9705681818181818\n",
      "f1_score 0.9706869627123251\n",
      "recall 0.9705681818181818\n",
      "precision 0.9710419343307393\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.98      0.98      0.98       795\n",
      "         eco       0.94      0.91      0.92       821\n",
      "        food       0.99      0.99      0.99       820\n",
      "      health       0.98      0.98      0.98       794\n",
      "     politic       0.89      0.94      0.91       790\n",
      "       porno       1.00      1.00      1.00       809\n",
      "    religion       0.99      0.99      0.99       780\n",
      "       sport       0.99      0.98      0.99       831\n",
      "        tech       0.95      0.96      0.96       816\n",
      "          tv       0.99      0.97      0.98       754\n",
      "     weather       0.99      0.97      0.98       790\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8800\n",
      "   macro avg       0.97      0.97      0.97      8800\n",
      "weighted avg       0.97      0.97      0.97      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[779   3   2   4   1   0   1   2   2   1   0]\n",
      " [  6 747   2   2  46   0   0   2  15   0   1]\n",
      " [  1   1 812   1   0   1   0   0   2   0   2]\n",
      " [  0   1   2 778   5   0   3   0   4   1   0]\n",
      " [  0  29   0   1 746   0   1   0   8   1   4]\n",
      " [  2   0   0   1   1 805   0   0   0   0   0]\n",
      " [  0   0   0   1   2   0 776   0   0   1   0]\n",
      " [  0   1   0   3   6   0   0 817   3   1   0]\n",
      " [  2  13   1   5   9   0   0   4 781   1   0]\n",
      " [  3   2   0   1  12   0   2   1   3 730   0]\n",
      " [  0   1   0   0  13   1   4   0   0   1 770]]\n",
      "DecisionTreeClassifier\n",
      "accuracy 0.8688636363636364\n",
      "f1_score 0.8695423465106071\n",
      "recall 0.8688636363636364\n",
      "precision 0.8731453481102255\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.92      0.90      0.91       795\n",
      "         eco       0.81      0.76      0.78       821\n",
      "        food       0.93      0.92      0.93       820\n",
      "      health       0.85      0.85      0.85       794\n",
      "     politic       0.76      0.75      0.75       790\n",
      "       porno       0.96      0.94      0.95       809\n",
      "    religion       0.94      0.96      0.95       780\n",
      "       sport       0.94      0.86      0.90       831\n",
      "        tech       0.85      0.83      0.84       816\n",
      "          tv       0.91      0.87      0.89       754\n",
      "     weather       0.72      0.92      0.81       790\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      8800\n",
      "   macro avg       0.87      0.87      0.87      8800\n",
      "weighted avg       0.87      0.87      0.87      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[714  13   6  17   4   7   3   3   8   4  16]\n",
      " [ 11 622   2  11  78   1   2   7  35   9  43]\n",
      " [ 11   1 758   7   0   5   0   2   4   4  28]\n",
      " [  2   6  26 675   7   1  11   4  20  10  32]\n",
      " [  4  60   2  17 594   5   7  14  21  12  54]\n",
      " [ 14   0   1   4   2 763   0   2   0   6  17]\n",
      " [  0   2   1   4   2   3 746   1   0   1  20]\n",
      " [  4  15   3  14  30   5   6 714   7   9  24]\n",
      " [  4  40   7  26  24   2   2   8 675   3  25]\n",
      " [  6   5   2  13  25   2   5   5  10 656  25]\n",
      " [  2   6   4   3  19   2  10   2  10   3 729]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AhOmar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "accuracy 0.9069318181818182\n",
      "f1_score 0.9072619536786113\n",
      "recall 0.9069318181818182\n",
      "precision 0.9093511145870439\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.95      0.95      0.95       795\n",
      "         eco       0.85      0.84      0.84       821\n",
      "        food       0.95      0.95      0.95       820\n",
      "      health       0.91      0.91      0.91       794\n",
      "     politic       0.83      0.80      0.81       790\n",
      "       porno       0.98      0.97      0.97       809\n",
      "    religion       0.96      0.96      0.96       780\n",
      "       sport       0.96      0.91      0.93       831\n",
      "        tech       0.91      0.85      0.88       816\n",
      "          tv       0.93      0.89      0.91       754\n",
      "     weather       0.78      0.94      0.85       790\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      8800\n",
      "   macro avg       0.91      0.91      0.91      8800\n",
      "weighted avg       0.91      0.91      0.91      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[754   6   3   4   2   3   1   2   5   3  12]\n",
      " [ 11 687   4   8  49   0   2   5  24   5  26]\n",
      " [  5   1 781   4   1   2   1   0   1   3  21]\n",
      " [  1   3  19 726   5   2   1   3   9   3  22]\n",
      " [  6  44   5  17 632   1   5   9  15   8  48]\n",
      " [  6   0   1   3   1 782   0   0   0   3  13]\n",
      " [  0   3   1   3   0   1 752   0   3   3  14]\n",
      " [  2   7   1   8  19   1   6 758   6   9  14]\n",
      " [  5  44   4  18  18   1   2   7 697   4  16]\n",
      " [  4   4   4   6  18   1   9   7   6 670  25]\n",
      " [  1   7   1   1  18   3   6   2   3   6 742]]\n"
     ]
    }
   ],
   "source": [
    "for classifier in cl:\n",
    "    featureextraction2(data,classifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.968178</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.968239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.939318</td>\n",
       "      <td>0.939861</td>\n",
       "      <td>0.939318</td>\n",
       "      <td>0.945708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.962386</td>\n",
       "      <td>0.962788</td>\n",
       "      <td>0.962386</td>\n",
       "      <td>0.963980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.968495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.085682</td>\n",
       "      <td>0.013524</td>\n",
       "      <td>0.085682</td>\n",
       "      <td>0.007341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.802386</td>\n",
       "      <td>0.819253</td>\n",
       "      <td>0.802386</td>\n",
       "      <td>0.880719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.970568</td>\n",
       "      <td>0.970687</td>\n",
       "      <td>0.970568</td>\n",
       "      <td>0.971042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.868864</td>\n",
       "      <td>0.869542</td>\n",
       "      <td>0.868864</td>\n",
       "      <td>0.873145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.906932</td>\n",
       "      <td>0.907262</td>\n",
       "      <td>0.906932</td>\n",
       "      <td>0.909351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier  dataset_size    Accuracy    f1_score    Recall   \\\n",
       "0           MultinomialNB         748827    0.968295    0.968178  0.968295   \n",
       "1             BernoulliNB         748827    0.939318    0.939861  0.939318   \n",
       "2      LogisticRegression         748827    0.962386    0.962788  0.962386   \n",
       "3           SGDClassifier         748827    0.968182    0.968200  0.968182   \n",
       "4                     SVC         748827    0.085682    0.013524  0.085682   \n",
       "5                   NuSVC         748827    0.802386    0.819253  0.802386   \n",
       "6               LinearSVC         748827    0.970568    0.970687  0.970568   \n",
       "7  DecisionTreeClassifier         748827    0.868864    0.869542  0.868864   \n",
       "8  RandomForestClassifier         748827    0.906932    0.907262  0.906932   \n",
       "\n",
       "    precision  \n",
       "0    0.968239  \n",
       "1    0.945708  \n",
       "2    0.963980  \n",
       "3    0.968495  \n",
       "4    0.007341  \n",
       "5    0.880719  \n",
       "6    0.971042  \n",
       "7    0.873145  \n",
       "8    0.909351  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.compat import StringIO\n",
    "\n",
    "nn = pd.read_csv(StringIO(result), sep='*')\n",
    "nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureextraction1Gram(data , clf):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data['text'], data['class1'],test_size=0.20, random_state = 0)\n",
    "    vectorizer = TfidfVectorizer( analyzer='word',smooth_idf=True, ngram_range=(1,2))#, norm='l2'.strip_accents='unicode',\n",
    "    vectorizer.fit(X_train)\n",
    "    #vectorizer.transform(X_test)\n",
    "    X_train_vectorized = vectorizer.transform(X_train)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    predictions = clf.predict(vectorizer.transform(X_test))\n",
    "    global result\n",
    "    result +=\"12gram\"+'*'+str(len(data))+'*'+str(accuracy_score(y_test, predictions))+'*'+str(f1_score(y_test,predictions,average='weighted'))+'*'+str(recall_score(y_test, predictions,average='weighted'))+'*'+str(precision_score(y_test, predictions,average='weighted'))+'\\n'\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"accuracy\",accuracy_score(y_test, predictions))\n",
    "    print(\"f1_score\",f1_score(y_test, predictions,average='weighted'))\n",
    "    print(\"recall\",recall_score(y_test, predictions,average='weighted'))\n",
    "    print(\"precision\",precision_score(y_test, predictions,average='weighted'))    \n",
    "    print ('\\n clasification report:\\n', classification_report(y_test, predictions))\n",
    "    print (' confussion matrix:\\n',confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureextraction2Gram(data , clf):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(data['text'], data['class1'],test_size=0.20, random_state = 0)\n",
    "    vectorizer = TfidfVectorizer( analyzer='word',smooth_idf=True, ngram_range=(2,2))#, norm='l2'.strip_accents='unicode',\n",
    "    vectorizer.fit(X_train)\n",
    "    #vectorizer.transform(X_test)\n",
    "    X_train_vectorized = vectorizer.transform(X_train)\n",
    "    clf.fit(X_train_vectorized, y_train)\n",
    "    predictions = clf.predict(vectorizer.transform(X_test))\n",
    "    global result \n",
    "    result +=\"bigram\"+'*'+str(len(data))+'*'+str(accuracy_score(y_test, predictions))+'*'+str(f1_score(y_test,predictions,average='weighted'))+'*'+str(recall_score(y_test, predictions,average='weighted'))+'*'+str(precision_score(y_test, predictions,average='weighted'))+'\\n'\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"accuracy\",accuracy_score(y_test, predictions))\n",
    "    print(\"f1_score\",f1_score(y_test, predictions,average='weighted'))\n",
    "    print(\"recall\",recall_score(y_test, predictions,average='weighted'))\n",
    "    print(\"precision\",precision_score(y_test, predictions,average='weighted'))    \n",
    "    print ('\\n clasification report:\\n', classification_report(y_test, predictions))\n",
    "    print (' confussion matrix:\\n',confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "accuracy 0.9672727272727273\n",
      "f1_score 0.9671016161129923\n",
      "recall 0.9672727272727273\n",
      "precision 0.9671681061977739\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.96      0.99      0.98       795\n",
      "         eco       0.94      0.90      0.92       821\n",
      "        food       1.00      0.99      0.99       820\n",
      "      health       0.96      0.99      0.97       794\n",
      "     politic       0.93      0.91      0.92       790\n",
      "       porno       0.99      0.99      0.99       809\n",
      "    religion       0.99      0.99      0.99       780\n",
      "       sport       0.98      0.98      0.98       831\n",
      "        tech       0.97      0.94      0.96       816\n",
      "          tv       0.95      0.98      0.96       754\n",
      "     weather       0.97      0.98      0.97       790\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      8800\n",
      "   macro avg       0.97      0.97      0.97      8800\n",
      "weighted avg       0.97      0.97      0.97      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[790   0   0   1   0   1   1   2   0   0   0]\n",
      " [ 19 742   2   4  27   0   0   6  11   6   4]\n",
      " [  2   0 811   3   0   1   0   0   0   1   2]\n",
      " [  0   1   0 784   2   0   3   0   2   1   1]\n",
      " [  2  30   1   3 719   2   3   5   7   6  12]\n",
      " [  1   0   0   2   0 803   0   0   0   1   2]\n",
      " [  1   0   0   2   1   0 771   0   0   3   2]\n",
      " [  0   0   0   3   2   0   1 817   2   5   1]\n",
      " [  4  17   1  11   9   0   0   4 767   3   0]\n",
      " [  2   1   0   2   5   4   1   2   1 736   0]\n",
      " [  1   1   0   0   5   0   1   0   0  10 772]]\n"
     ]
    }
   ],
   "source": [
    "featureextraction1Gram(data,MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "accuracy 0.8922727272727272\n",
      "f1_score 0.8976661068575132\n",
      "recall 0.8922727272727272\n",
      "precision 0.9172489100055146\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ads       0.94      0.96      0.95       795\n",
      "         eco       0.90      0.79      0.84       821\n",
      "        food       0.98      0.87      0.92       820\n",
      "      health       0.94      0.90      0.92       794\n",
      "     politic       0.90      0.71      0.80       790\n",
      "       porno       0.99      0.96      0.98       809\n",
      "    religion       0.99      0.94      0.96       780\n",
      "       sport       0.97      0.92      0.94       831\n",
      "        tech       0.95      0.84      0.89       816\n",
      "          tv       0.55      0.97      0.70       754\n",
      "     weather       0.95      0.96      0.95       790\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      8800\n",
      "   macro avg       0.92      0.89      0.90      8800\n",
      "weighted avg       0.92      0.89      0.90      8800\n",
      "\n",
      " confussion matrix:\n",
      " [[767   4   0   4   1   2   1   1   3   9   3]\n",
      " [ 15 645   1   5  34   0   0   4  18  94   5]\n",
      " [  2   0 715   6   0   1   0   1   0  94   1]\n",
      " [  6   1   8 716   5   0   3   4   4  43   4]\n",
      " [  0  33   1   9 563   0   0   9   4 156  15]\n",
      " [  2   0   0   0   0 776   0   0   0  30   1]\n",
      " [  0   0   0   1   3   0 736   0   0  38   2]\n",
      " [  1   2   0   4   3   1   1 762   2  49   6]\n",
      " [ 15  28   1  15   9   0   1   4 682  58   3]\n",
      " [  3   2   0   3   7   1   2   2   2 731   1]\n",
      " [  2   1   0   1   1   1   2   0   1  22 759]]\n"
     ]
    }
   ],
   "source": [
    "featureextraction2Gram(data,MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.compat import StringIO\n",
    "\n",
    "nn = pd.read_csv(StringIO(result), sep='*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>dataset_size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.968178</td>\n",
       "      <td>0.968295</td>\n",
       "      <td>0.968239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.939318</td>\n",
       "      <td>0.939861</td>\n",
       "      <td>0.939318</td>\n",
       "      <td>0.945708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.962386</td>\n",
       "      <td>0.962788</td>\n",
       "      <td>0.962386</td>\n",
       "      <td>0.963980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.968200</td>\n",
       "      <td>0.968182</td>\n",
       "      <td>0.968495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.085682</td>\n",
       "      <td>0.013524</td>\n",
       "      <td>0.085682</td>\n",
       "      <td>0.007341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NuSVC</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.802386</td>\n",
       "      <td>0.819253</td>\n",
       "      <td>0.802386</td>\n",
       "      <td>0.880719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.970568</td>\n",
       "      <td>0.970687</td>\n",
       "      <td>0.970568</td>\n",
       "      <td>0.971042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.868864</td>\n",
       "      <td>0.869542</td>\n",
       "      <td>0.868864</td>\n",
       "      <td>0.873145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>748827</td>\n",
       "      <td>0.906932</td>\n",
       "      <td>0.907262</td>\n",
       "      <td>0.906932</td>\n",
       "      <td>0.909351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12gram</td>\n",
       "      <td>44000</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.967168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bigram</td>\n",
       "      <td>44000</td>\n",
       "      <td>0.892273</td>\n",
       "      <td>0.897666</td>\n",
       "      <td>0.892273</td>\n",
       "      <td>0.917249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Classifier  dataset_size    Accuracy    f1_score    Recall   \\\n",
       "0            MultinomialNB         748827    0.968295    0.968178  0.968295   \n",
       "1              BernoulliNB         748827    0.939318    0.939861  0.939318   \n",
       "2       LogisticRegression         748827    0.962386    0.962788  0.962386   \n",
       "3            SGDClassifier         748827    0.968182    0.968200  0.968182   \n",
       "4                      SVC         748827    0.085682    0.013524  0.085682   \n",
       "5                    NuSVC         748827    0.802386    0.819253  0.802386   \n",
       "6                LinearSVC         748827    0.970568    0.970687  0.970568   \n",
       "7   DecisionTreeClassifier         748827    0.868864    0.869542  0.868864   \n",
       "8   RandomForestClassifier         748827    0.906932    0.907262  0.906932   \n",
       "9                   12gram          44000    0.967273    0.967102  0.967273   \n",
       "10                  bigram          44000    0.892273    0.897666  0.892273   \n",
       "\n",
       "     precision  \n",
       "0     0.968239  \n",
       "1     0.945708  \n",
       "2     0.963980  \n",
       "3     0.968495  \n",
       "4     0.007341  \n",
       "5     0.880719  \n",
       "6     0.971042  \n",
       "7     0.873145  \n",
       "8     0.909351  \n",
       "9     0.967168  \n",
       "10    0.917249  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
